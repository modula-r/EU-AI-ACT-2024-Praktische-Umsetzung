# EU-AI-ACT-Praktische-Umsetzung
In diesem Repository behandeln wir eine praktische Umsetzung, innerhalb einer bild-generativen Arbeitsumgebung via ComfyUI. 


ğŸ“„ Executive Summary

Die rasante Verbreitung generativer KIâ€‘Systeme wie Stable Diffusion erÃ¶ffnet enorme kreative und wirtschaftliche Potenziale. Gleichzeitig entstehen neue Herausforderungen im Hinblick auf Transparenz, Verantwortung und rechtliche KonformitÃ¤t â€“ insbesondere durch die Vorgaben des europÃ¤ischen AI Act 2024.

modulaâ€‘r | Audit Blueprint adressiert genau diese LÃ¼cke: Es ist ein modulares, quelloffenes Konzept fÃ¼r vollstÃ¤ndig prÃ¼fbare und AIâ€‘Actâ€‘konforme KIâ€‘Workflows. Entwickelt aus einer klaren Whiteâ€‘Hatâ€‘Haltung heraus, verbindet das Blueprint technische Auditâ€‘Funktionen mit ethischem Anspruch: Ziel ist es, die QualitÃ¤t und VertrauenswÃ¼rdigkeit von KIâ€‘Ergebnissen dauerhaft sicherzustellen â€“ nicht durch nachtrÃ¤gliche Kontrolle, sondern bereits durch integrierte Auditâ€‘Technologie im Entstehungsprozess.

Dieses Repository soll zeigen, wie mit speziell entwickelten Auditâ€‘Nodes (z.â€¯B. PromptComplianceCheckerNode, LoRAContextCaptureNode, MetaWatermarkNode) ein vollstÃ¤ndiger Nachweis der Modellâ€‘, Promptâ€‘ und LoRAâ€‘Verwendung gefÃ¼hrt werden kann â€“ verschlÃ¼sselt, hashâ€‘verkettet und nachvollziehbar dokumentiert. So entsteht ein Werkzeugkasten, der kleine Teams wie auch grÃ¶ÃŸere Organisationen dabei unterstÃ¼tzt, die Anforderungen des AI Act 2024 und kÃ¼nftiger Regulierungen zu erfÃ¼llen â€“ frei von Drittanbieterâ€‘Bindungen und mit hÃ¶chstem Anspruch an IntegritÃ¤t und Datenschutz.



2ï¸âƒ£ Problemstellung & Motivation

Mit dem Aufkommen leistungsfÃ¤higer Bildâ€‘ und Medienâ€‘KI wie Stable Diffusion hat sich die kreative Arbeit demokratisiert â€“ jeder kann heute KIâ€‘Modelle einsetzen, kombinieren oder erweitern. Doch mit dieser Freiheit wÃ¤chst auch die Verantwortung:

Transparenzpflichten sind je nach Einstufung des AI Act 2024 einzuhalten und mÃ¼ssen genau dokumentieren, welche Modelle, LoRAs, Prompts und Parameter verwendet wurden.

RechtskonformitÃ¤t erfordert, dass Urheberrechte, Lizenzbedingungen und Haftungsfragen jederzeit Ã¼berprÃ¼fbar sind.

Nachvollziehbarkeit wird zur Grundlage fÃ¼r Vertrauen â€“ nicht nur fÃ¼r Nutzer, sondern auch fÃ¼r PrÃ¼fer, Auftraggeber und die Ã–ffentlichkeit.

Aktuell fehlt dafÃ¼r ein praktikabler, auditierbarer Standard:

Workflows in Tools wie ComfyUI sind hochgradig flexibel â€“ aber oft intransparent.

Logs, Metadaten oder Parameterlisten werden manuell gefÃ¼hrt oder sind unvollstÃ¤ndig.

NachtrÃ¤gliche Analysen sind mÃ¶glich, aber weder standardisiert noch fÃ¤lschungssicher.

modulaâ€‘r | Audit Blueprint setzt genau hier an:
Anstatt Kontrolle als externen Prozess zu verstehen, wird Auditâ€‘FÃ¤higkeit von Anfang an in die KIâ€‘Pipeline integriert.
So entstehen nicht nur sichere Logs und Wasserzeichen, sondern ein grundlegendes â€Whiteâ€‘Hatâ€‘Frameworkâ€œ: fÃ¼r verantwortungsvolle KIâ€‘Nutzung, dokumentierte Prozesse und echte AIâ€‘Actâ€‘Compliance â€“ ohne dass dies die kreative Freiheit einschrÃ¤nkt.



3ï¸âƒ£ LÃ¶sung & Architektur

Der modulaâ€‘r | Audit Blueprint ist ein modular aufgebautes Framework, das nahtlos in bestehende ComfyUIâ€‘Workflows integriert wird. Sein Kernansatz: Auditâ€‘FÃ¤higkeit wird nicht nachtrÃ¤glich aufgesetzt, sondern als Bestandteil der kreativen Pipeline mitgedacht.

Die LÃ¶sung besteht aus vier zentralen Bausteinen:



ğŸŸ© 3.1 Auditâ€‘Nodes & Logging

Speziell entwickelte Nodes wie:

- PromptComplianceCheckerNode

- PromptModelLoggerNode

- LoRAContextCaptureNode

zeichnen wÃ¤hrend der Generierung automatisch alle wesentlichen Parameter auf:

- genutzte Modelle & LoRAs (inkl.MetaHeader)

- positive & negative Prompts

- Zeitstempel

- Userâ€‘ID oder Projektkennung
- zusÃ¤tzliche auditfÃ¤hige Informationen/Parameter

Die Daten werden verschlÃ¼sselt in Auditâ€‘Logs via Hashâ€‘Ketten abgelegt. So entsteht ein lÃ¼ckenloser, nachprÃ¼fbarer Verlauf â€“ auch fÃ¼r externe PrÃ¼fer.



ğŸŸ¨ 3.2 Metadatenâ€‘Wasserzeichen

Parallel dazu wird ein fÃ¤lschungssicherer Metadatenâ€‘Block (â€MetaWatermarkâ€œ) direkt in die exportierten Bildâ€‘Dateien (PNG, JPEG, ...) eingebettet:

- AIâ€‘Actâ€‘Transparenzhinweis

- Modellâ€‘ und LoRAâ€‘Informationen

- Auditâ€‘Hash zur VerknÃ¼pfung mit dem Log

Damit ist auch ohne Zugriff auf Logs ein direkter Nachweis im Bild enthalten, wenn das Produkt in die Ã¶ffentliche Verwendung Ã¼bergeht.



ğŸŸ¦ 3.3 PrÃ¼froutinen & Frontend

Eine webbasierte OberflÃ¤che (z.â€¯B. â€Auditâ€‘Dashboardâ€œ) erlaubt:

- Sichtung & Filterung der Logs

- PrÃ¼fung, ob Auditâ€‘Nodes korrekt eingebunden wurden

- Signaturâ€‘ und Hashâ€‘Verifikation

FÃ¼r den Nutzer ist das Frontend rein lesend â€“ Ã„nderungen am Log sind technisch ausgeschlossen.



ğŸŸ¥ 3.4 IntegritÃ¤t & Compliance

Alle Logs werden AESâ€‘verschlÃ¼sselt abgelegt. Die PrÃ¼fkette ist so aufgebaut, dass:

- jedes Log einen Hashâ€‘Zeiger auf das vorherige enthÃ¤lt (Blockchainâ€‘Prinzip)

- Manipulationen sofort erkennbar wÃ¤ren

- PrÃ¼fer jederzeit verifizieren kÃ¶nnen, dass generierte Inhalte den dokumentierten Parametern entsprechen

Ergebnis:
Ein vollstÃ¤ndig auditierbarer, AIâ€‘Actâ€‘konformer Workflow â€“ ohne die kreative Freiheit des Nutzers einzuschrÃ¤nken.



4ï¸âƒ£ Technische Details & Implementierung

Der modulaâ€‘r | Audit Blueprint verbindet bestehende KIâ€‘Workflows mit einer robusten Complianceâ€‘Schicht â€“ realisiert als modulare Pythonâ€‘Nodes und verschlÃ¼sseltes Loggingâ€‘System. Die Architektur ist vollstÃ¤ndig openâ€‘sourceâ€‘fÃ¤hig und so dokumentiert, dass PrÃ¼fer sie unabhÃ¤ngig nachvollziehen kÃ¶nnen.


ğŸ”§ 4.1 Nodeâ€‘Architektur
Die Auditâ€‘FunktionalitÃ¤ten sind in eigene Customâ€‘Nodes gekapselt:

PromptComplianceCheckerNode: prÃ¼ft Prompts gegen Blacklists(negative Injections) & AIâ€‘Actâ€‘Kriterien

LoRAContextCaptureNode: protokolliert genutzte Model/LoRAâ€‘Dateien samt Zeitstempel & Hash

MetaWatermarkNode: bettet AIâ€‘Actâ€‘relevante Daten in Bildâ€‘Metadaten ein

AuditLogReaderNode: stellt Logs geprÃ¼ft lesbar dar (Auditor only)

Alle Nodes nutzen ein einheitliches Loggingâ€‘Interface, sodass Erweiterungen (z.â€¯B. weitere PrÃ¼fkriterien) einfach mÃ¶glich sind.


ğŸ“¦ 4.2 Logging & VerschlÃ¼sselung

Logs werden in Echtzeit wÃ¤hrend der Inferenz geschrieben:

Als JSONâ€‘Objekte mit allen relevanten Feldern (Prompts, Modelle, LoRAs, Zeitstempel, Complianceâ€‘Hinweisen)

Jeder Logâ€‘Eintrag enthÃ¤lt:

prev_hash â†’ PrÃ¼fkette

audit_hash â†’ eindeutige ID des Vorgangs

Vor dem Speichern werden EintrÃ¤ge mit AESâ€‘256 verschlÃ¼sselt und als base64 codiert abgelegt.
So ist sichergestellt, dass Logs weder nachtrÃ¤glich verÃ¤ndert noch eingesehen werden kÃ¶nnen â€“ auÃŸer durch berechtigte PrÃ¼fer mit SchlÃ¼ssel.

<img width="1222" height="510" alt="modelaudit2" src="https://github.com/user-attachments/assets/5595ebf0-574d-4d97-9719-403c381e37ad" />


ğŸ–¼ 4.3 Metadatenâ€‘Einbettung

Jede generierte Bilddatei enthÃ¤lt:

- AIâ€‘Actâ€‘Transparenzâ€‘Statement (ai_generated: true)

- verwendetes Modell & LoRAâ€‘Namen

- Auditâ€‘Hash zur VerknÃ¼pfung mit Logs

- Erstellungszeitpunkt & Toolâ€‘Version

Die Metadaten werden in:

- PNG: als tEXtâ€‘Chunks (Ã¼ber PngInfo)

- JPEG: als UserComment im EXIFâ€‘Block

eingebettet. So bleiben die Daten bei Weitergabe des Bildes erhalten.


ğŸ›¡ 4.4 Schutz vor Manipulation

Mehrschichtiger Schutz:

- Logs sind verkettet & verschlÃ¼sselt

- Metadaten sind Teil des Bildes (FÃ¤lschung erkennbar Ã¼ber Hash)

- PrÃ¼froutine beim Start prÃ¼ft, ob alle Auditâ€‘Nodes geladen & aktiv sind

- Frontend verhindert Workflowâ€‘Start, wenn PrÃ¼fkette fehlt


ğŸ§© 4.5 Erweiterbarkeit & Open Source

Modular aufgebaut: neue Nodes kÃ¶nnen dieselbe Loggingâ€‘API nutzen

Kompatibel mit bestehenden ComfyUIâ€‘Workflows

Keine Vendorâ€‘Lockâ€‘Ins: entwickelt ohne Drittanbieterâ€‘AbhÃ¤ngigkeit

Dokumentation als Whitepaper & Ã¶ffentliches Gitâ€‘Repository geplant und hier umgesetzt (laufende Updates/Versionierungen)



ğŸ“œ 5.1 AIâ€‘Actâ€‘Grundanforderungen

Der AI Act fordert u.â€¯a.:

- Transparenzpflicht fÃ¼r Foundation Models (Art.â€¯50): Angaben zu Modell, Trainingsdaten, Einsatzbereich

- Protokollierungspflicht (Art.â€¯53): Dokumentation der Modellâ€‘Verwendung & Parametrisierung

- Kennzeichnungspflicht fÃ¼r KIâ€‘generierte Inhalte (Art.â€¯52)

- MaÃŸnahmen zur Risikominimierung und PrÃ¼fbarkeit sowie einer umfassenden technischen Dokumentation, wenn die Form (Betreiber/Hersteller) dargestellt ist.



âœ… 5.2 Umsetzung im Blueprint

Vorgabe (AI Act)	Umsetzung im Blueprint

- Modellâ€‘ und Trainingsdatenâ€‘Angabe

- Logs & Metadaten enthalten model_filename (techn.audifizierbar), Meta-Header, LoRAâ€‘Infos & Hinweise zu Datenrechten

- Transparenz fÃ¼r Endnutzer	Automatisch eingebettete AIâ€‘Actâ€‘Metadaten (ai_generated, Toolâ€‘Version etc.).

- PrÃ¼fbarkeit & Protokollierung	Verkettete, verschlÃ¼sselte JSONâ€‘Logs mit vollstÃ¤ndiger Inferenzhistorie.

- Nachvollziehbarkeit von Ã„nderungen	prev_hash und audit_hash bilden eine unverÃ¤nderbare PrÃ¼fkette.

- Schutz vor Manipulation	AESâ€‘256â€‘VerschlÃ¼sselung & PrÃ¼froutinen im Workflow.

- Kennzeichnung KIâ€‘Inhalt	Expliziter Metadatenâ€‘Tag + optionaler visueller Wasserzeichenâ€‘Layer. (modula-r.com LogoInformer.json)

- LRA-Shield, Revision der vorhandenen Low Rank Modelle und zertifizierten Workflows. (Opensource by modula-r.com)


ğŸ›¡ 5.3 Ãœber die reine Pflicht hinaus

Der Blueprint geht bewusst Ã¼ber Mindestpflichten hinaus:

- Automatisiertes Logging statt manueller Dokumentation

- Verifizierbare PrÃ¼fkette (Blockchainâ€‘Ã¤hnlich) auch fÃ¼r interne LoRAâ€‘Wechsel

- VerschlÃ¼sselung aller Logs inkl. Vorhaltepflichtâ€‘KompatibilitÃ¤t

- Frontendâ€‘PrÃ¼fung vor jeder AusfÃ¼hrung: verhindert unprotokollierte Runs

- Promptâ€‘PrÃ¼fung mit optionalen AIâ€‘Actâ€‘Blacklists



ğŸ· 5.4 Hinweis zu Trainingsdaten

Der AI Act verpflichtet zur Dokumentation der Rechtebasis der Trainingsdaten.

Bei nicht lÃ¼ckenlos dokumentierten Daten wird ein Transparenzâ€‘Hinweis protokolliert & in Metadaten Ã¼bernommen.

So wird die Rechtsunsicherheit transparent gemacht, PrÃ¼fer kÃ¶nnen Risiken bewerten.



ğŸ§© 5.5 Zukunftssicherheit

Architektur ist modular & updatefÃ¤hig fÃ¼r kÃ¼nftige Regulierungen

Anpassbar an neue Standards (z.â€¯B. ISO/IEC 42001)

PrÃ¼ffÃ¤hig durch externe Stellen & Auditâ€‘APIs mÃ¶glich




6ï¸âƒ£ Ausblick & gesellschaftliche Bedeutung


ğŸŒ 6.1 Gesellschaftlicher Kontext

Die rasante Verbreitung von KI-Systemen verÃ¤ndert unsere Welt tiefgreifend â€“ in Wirtschaft, Kultur und Alltag. Gleichzeitig wachsen die Herausforderungen in den Bereichen Ethik, Datenschutz, Sicherheit und Urheberrecht. Hier setzt der modulaâ€‘r Audit Blueprint an:

Vertrauen schaffen: Durch transparente Nachvollziehbarkeit und verlÃ¤ssliche Auditierbarkeit wird das Vertrauen von Nutzer:innen, Unternehmen und RegulierungsbehÃ¶rden gestÃ¤rkt.

Verantwortung Ã¼bernehmen: Der Blueprint zeigt, wie technisch-ethische Verantwortung aktiv umgesetzt werden kann â€“ insbesondere im White-Hat-Umfeld.

Demokratische Teilhabe fÃ¶rdern: Offenlegung und PrÃ¼fbarkeit beugen Machtkonzentrationen vor und ermÃ¶glichen eine gerechte KI-Entwicklung.


ğŸ”® 6.2 Technologische Perspektive

Die KI-Auditing-Landschaft entwickelt sich dynamisch weiter. Der Blueprint ist bewusst modular, erweiterbar und kompatibel mit zukÃ¼nftigen Standards und Werkzeugen.

Integration von KI-ErklÃ¤rbarkeit: KÃ¼nftige Module kÃ¶nnten ErklÃ¤rungen zu Entscheidungen der KI liefern (XAI).

Automatisierte Risikoanalysen: KI-gestÃ¼tzte Auditassistenten kÃ¶nnten Risiken frÃ¼hzeitig erkennen und proaktiv eingreifen.

Community-Driven Auditing: Dezentrale PrÃ¼fer-Netzwerke mit Blockchain-Sicherung sind denkbar.


ğŸ¤ 6.3 Gesellschaftliche Verantwortung

Der modula-r Audit Blueprint ist mehr als ein technisches Framework: Er ist Ausdruck eines White-Hat-Mindsets, das KI als Chance fÃ¼r alle begreift.

Ethik als Kernprinzip: Technik und Gesellschaft sind untrennbar verbunden â€“ verantwortungsvoller KI-Einsatz fÃ¶rdert soziale Gerechtigkeit.

Bildung & AufklÃ¤rung: Transparente KI-Systeme unterstÃ¼tzen informierte Entscheidungen und stÃ¤rken demokratische Prozesse.

InnovationsfÃ¶rderung: Compliance und Transparenz sind keine Hemmnisse, sondern Enabler fÃ¼r nachhaltige Innovation.



âœ¨ 6.4 Schlusswort

Wir stehen am Anfang einer neuen Ã„ra â€“ einer Ã„ra, in der KI-Systeme unsere RealitÃ¤t prÃ¤gen. Mit dem modulaâ€‘r Audit Blueprint gestalten wir diese Zukunft verantwortungsbewusst, transparent und ethisch fundiert.

Gemeinsam kÃ¶nnen wir KI als Werkzeug fÃ¼r eine bessere, sichere und gerechte Welt nutzen.

Mitwirkende dieser Verfassung:
Anni Strauss - Bremen
Tim SchÃ¶rger - Bremen
Aida â€“ KI mit White-Hat-Seele und demokratischem VerstÃ¤ndnis.


Vermerk 24.08.2025: Dieses Repository im allgemeinen unterliegt einer kontinuierlichen Aktualisierung/Wartung. Informationen zu Inhalten, technischen Funktionen oder weiteren Inhalten kÃ¶nnen sich in diesem Prozess Ã¤ndern! Updatevermerke werden deutlich gemacht.
